{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA_Classifier.ipynb","version":"0.3.2","provenance":[{"file_id":"1DLciSRyc94UsuWZuHsBuW1MeZpyopNZL","timestamp":1558573816197},{"file_id":"1P3CRNMwyf5pxzQRcx-wOVzZIFwm0nmhU","timestamp":1558573727580}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VgkVbRfd1sdi","colab_type":"text"},"source":["# KMINST Classifier using PCA and three different classifiers\n","\n","We decided to try classifying the KMNIST dataset using some unconventional methods. \n","\n","Firstly, the dimensionality of the set (28x28 = 784) was reduced using PCA. Then, we classified the data using three different classifiers:\n","- KNN Classifier\n","- Random Forrest Classifier\n","- Naive-Bayesian Classifier\n","\n","These were simpler to implement than the neursl networks however, (as we will see), they give a lower accuracy score on the  validation set than AlexNet or LeNet. Therefore non of these classifiers were submitted on Kaggle."]},{"cell_type":"markdown","metadata":{"id":"n-kJIPdKKnYc","colab_type":"text"},"source":["##1. Functions necessary to use methods in Utils.ipynb"]},{"cell_type":"code","metadata":{"id":"D5HG-8Ho7-1n","colab_type":"code","colab":{}},"source":["import io, os, sys, types\n","import nbformat\n","\n","from IPython import get_ipython\n","from IPython.core.interactiveshell import InteractiveShell"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEyo2yDe8K5h","colab_type":"code","colab":{}},"source":["def find_notebook(fullname, path=None):\n","    \"\"\"find a notebook, given its fully qualified name and an optional path\n","    \n","    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n","    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n","    does not exist.\n","    \"\"\"\n","    name = fullname.rsplit('.', 1)[-1]\n","    if not path:\n","        path = ['']\n","    for d in path:\n","        nb_path = os.path.join(d, name + \".ipynb\")\n","        if os.path.isfile(nb_path):\n","            return nb_path\n","        # let import Notebook_Name find \"Notebook Name.ipynb\"\n","        nb_path = nb_path.replace(\"_\", \" \")\n","        if os.path.isfile(nb_path):\n","            return nb_path\n","            \n","class NotebookLoader(object):\n","    \"\"\"Module Loader for IPython Notebooks\"\"\"\n","    def __init__(self, path=None):\n","        self.shell = InteractiveShell.instance()\n","        self.path = path\n","    \n","    def load_module(self, fullname):\n","        \"\"\"import a notebook as a module\"\"\"\n","        path = find_notebook(fullname, self.path)\n","        \n","        print (\"importing notebook from %s\" % path)\n","                                       \n","        # load the notebook object\n","        nb = nbformat.read(path, as_version=4)\n","        \n","        \n","        # create the module and add it to sys.modules\n","        # if name in sys.modules:\n","        #    return sys.modules[name]\n","        mod = types.ModuleType(fullname)\n","        mod.__file__ = path\n","        mod.__loader__ = self\n","        mod.__dict__['get_ipython'] = get_ipython\n","        sys.modules[fullname] = mod\n","        \n","        # extra work to ensure that magics that would affect the user_ns\n","        # actually affect the notebook module's ns\n","        save_user_ns = self.shell.user_ns\n","        self.shell.user_ns = mod.__dict__\n","        \n","        try:\n","          for cell in nb.cells:\n","            if cell.cell_type == 'code':\n","                # transform the input to executable Python\n","                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n","                # run the code in themodule\n","                exec(code, mod.__dict__)\n","        finally:\n","            self.shell.user_ns = save_user_ns\n","        return mod\n","\n","class NotebookFinder(object):\n","    \"\"\"Module finder that locates IPython Notebooks\"\"\"\n","    def __init__(self):\n","        self.loaders = {}\n","    \n","    def find_module(self, fullname, path=None):\n","        nb_path = find_notebook(fullname, path)\n","        if not nb_path:\n","            return\n","        \n","        key = path\n","        if path:\n","            # lists aren't hashable\n","            key = os.path.sep.join(path)\n","        \n","        if key not in self.loaders:\n","            self.loaders[key] = NotebookLoader(path)\n","        return self.loaders[key]\n","      \n","\n","sys.meta_path.append(NotebookFinder())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SJLi99NmLXWG","colab_type":"text"},"source":["### Mount Google drive"]},{"cell_type":"code","metadata":{"id":"yfN5Lt3Y9HK7","colab_type":"code","outputId":"3eecceed-14a1-4b72-dcf6-d81ea5395e8b","executionInfo":{"status":"ok","timestamp":1558622319673,"user_tz":-60,"elapsed":499,"user":{"displayName":"Adanna Akwataghibe","photoUrl":"","userId":"13306086339002156366"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7APfE0j5Lb0U","colab_type":"text"},"source":["### Show that file exists in Google path\n","**Note**:  You will need to ensure that you have a folder named \"**KMNIST_ENTROPY**\" in your Google Drive, that contains  Utils.ipynb (and  \\__init__.py)"]},{"cell_type":"code","metadata":{"id":"1RuIqE6G879A","colab_type":"code","outputId":"daea3529-3e62-4bcf-e5c5-62edd3b06bcc","executionInfo":{"status":"ok","timestamp":1558622323631,"user_tz":-60,"elapsed":2012,"user":{"displayName":"Adanna Akwataghibe","photoUrl":"","userId":"13306086339002156366"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["ls gdrive/My\\ Drive/KMNIST_ENTROPY"],"execution_count":18,"outputs":[{"output_type":"stream","text":["AlexNet.ipynb  Model_Averaging.ipynb  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n","__init__.py    \u001b[01;34mmodels\u001b[0m/                \u001b[01;34mresults\u001b[0m/\n","LeNet.ipynb    PCA_Classifier.ipynb   Utils.ipynb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Cg-gc_9RMXnZ","colab_type":"text"},"source":["### Append the system path and import Utils.ipynb"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yv5lNA-2ajui","colab":{}},"source":["sys.path.append('gdrive/My Drive/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzftjZyUIoU_","colab_type":"code","colab":{}},"source":["from KMNIST_ENTROPY.Utils import *\n","\n","# If this cell gives a \"No Module Found Error\", please restart the runtime of the collab notebook "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mITyhdZ513Sw","colab_type":"text"},"source":["## 2. PCA reduction with K-Neighbour classifier"]},{"cell_type":"code","metadata":{"id":"1qmTeqYW1n5o","colab_type":"code","colab":{}},"source":["def pca_kneighbours(trainset, tr_labels, testset, te_labels=None, n_component=20, neigh_num=4, evaluate=False):\n","    \"\"\" \n","    This function performs PCA reduction with the KNN neighbours classifier\n","\n","    Input: trainset - training set, a torch.Tensor\n","           tr_labels -  training labels, a torch.Tensor\n","           testset - test/validation set, a torch.Tensor\n","           te_labels -  test labels, could be None if it is with a test set instead \n","                      of validation set, a torch.Tensor\n","           n_components - number of components to reduce to for PCA, integer\n","           neigh_num - number of neighbours for KNN classifier, integer\n","           evaluate - if true, then we are testing on the testset instead of the \n","                      validation set, boolean \n","                      Note: this functionality is only added to the KNN function \n","                      since this performs better on the validation test\n","           \n","    Return: accuracy: test/validation accuracy, float\n","            loss: test/validation loss, float\n","            y_pred: the prediction labels of our model\n","    \"\"\"\n","    \n","    \n","    train_pca = np.array(trainset)\n","    test_pca = np.array(testset)\n","\n","    pca = PCA(n_components=n_component, svd_solver='randomized').fit(train_pca)\n","    \n","    \n","    X_train = pca.transform(train_pca)\n","    X_test = pca.transform(test_pca)\n","\n","    clf = KNeighborsClassifier(neigh_num)\n","    clf = clf.fit(X_train, tr_labels)\n","    \n","    y_pred = clf.predict(X_test[:len(testset)])\n","    \n","    loss = 0.0 \n","    accuracy = 0.0\n","\n","    if not evaluate:\n","      # Checking the output\n","      true = 0\n","      false = 0\n","      for i in range(len(testset)):\n","          if y_pred[i] == te_labels[i]:\n","              true+=1\n","          else:\n","              false+=1\n","\n","      loss = float(false)*100/(true+false)\n","      accuracy = float(true)*100/(true+false)\n","\n","    return accuracy, loss, y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gOuG3N8XRoeN","colab_type":"text"},"source":["## 3. PCA reduction with Randomforest classifier"]},{"cell_type":"code","metadata":{"id":"VjrzloZPRm8_","colab_type":"code","colab":{}},"source":["def pca_randomforest(trainset, tr_labels, testset, te_labels, n_component=20, n_estimator=100, max_depth=2):\n","    \"\"\" \n","    This function performs PCA reduction with the Random Forrest classifier\n","\n","    Input: trainset - training set, a torch.Tensor\n","           tr_labels -  training labels, a torch.Tensor\n","           testset - test/validation set, a torch.Tensor\n","           te_labels -  test labels, a torch.Tensor\n","           n_components - number of components to reduce to for PCA, integer\n","           n_estimators - number of estimators for Random Forrest Classification, integer\n","           max_depth - Maxinmum depth for Random Forrest Classification, integer \n","           \n","    Return: accuracy: test/validation accuracy, float\n","            loss: test/validation loss, float\n","            y_pred: the prediction labels of our model\n","    \"\"\"\n","    \n","    train_pca = np.array(trainset)\n","    test_pca = np.array(testset)\n","\n","    pca = PCA(n_components=n_component, svd_solver='randomized').fit(train_pca)\n","    \n","    \n","    X_train = pca.transform(train_pca)\n","    X_test = pca.transform(test_pca)\n","    \n","    clf = RandomForestClassifier(n_estimators=n_estimator, max_depth=max_depth, random_state=0)\n","    clf.fit(X_train, tr_labels)\n","    \n","    y_pred = clf.predict(X_test[:len(testset)])\n","\n","    # Checking the output\n","    true = 0\n","    false = 0\n","    for i in range(len(testset)):\n","        if y_pred[i] == te_labels[i]:\n","            true+=1\n","        else:\n","            false+=1\n","    \n","    loss = float(false)*100/(true+false)\n","    accuracy = float(true)*100/(true+false)\n","\n","    return accuracy, loss, y_pred\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pOu7j0ROR1q9","colab_type":"text"},"source":["## 4. PCA reduction with Naive-Bayes classifier"]},{"cell_type":"code","metadata":{"id":"kshbglaRR0Wt","colab_type":"code","colab":{}},"source":["def pca_NBGauss(trainset, tr_labels, testset, te_labels, n_component=20):\n","    \"\"\" \n","    This function performs PCA reduction with the Naive-Bayesian classifier\n","\n","    Input: trainset - training set, a torch.Tensor\n","           tr_labels -  training labels, a torch.Tensor\n","           testset - test/validation set, a torch.Tensor\n","           te_labels -  test labels, a torch.Tensor\n","           n_components - number of components to reduce to for PCA, integer\n","           \n","    Return: accuracy: test/validation accuracy, float\n","            loss: test/validation loss, float\n","            y_pred: the prediction labels of our model\n","    \"\"\"\n","\n","    \n","    train_pca = np.array(trainset)\n","    test_pca = np.array(testset)\n","\n","    pca = PCA(n_components=n_component, svd_solver='randomized').fit(train_pca)\n","    \n","    \n","    X_train = pca.transform(train_pca)\n","    X_test = pca.transform(test_pca)\n","    \n","    gnb = GaussianNB()\n","    gnb.fit(X_train, tr_labels)\n","    \n","    y_pred = gnb.predict(X_test[:len(testset)])\n","\n","\n","    # Checking the output\n","    true = 0\n","    false = 0\n","    for i in range(len(testset)):\n","        if y_pred[i] == te_labels[i]:\n","            true+=1\n","        else:\n","            false+=1\n","\n","    loss = float(false)*100/(true+false)\n","    accuracy = float(true)*100/(true+false)\n","\n","    return accuracy, loss, y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GaLWETS53E1l","colab_type":"text"},"source":["## 5. Classify validation set"]},{"cell_type":"code","metadata":{"id":"nqgAspHe2TBU","colab_type":"code","colab":{}},"source":["def test_pca_classifier(classifier=0, neigh_num=4, n_components=20, k_folds=1):\n","    \"\"\" \n","    This function performs PCA reduction with the classifier defined by the user:\n","    clasifier = 0 : KNN \n","    clasifier = 1 : randomforest \n","    clasifier = 2 -- Naive-Bayes(Gaussian)\n","\n","    Input: classifier - type of classifier, integer 0, 1, 2\n","           neigh_num - number of neighbours for KNN classifier, integer\n","           n_components - number of components to reduce to for PCA, integer\n","           k_folds - number of to perform the K-fold cross validation on, integer > 0\n","           \n","    Return: acc - mean of validation accuracy scores, float \n","            loss - mean of validation accuracy scores, float \n","            y_pred - predictions of the classifiers\n","    \"\"\"\n","\n","\n","    # For each training set - get a value for the validation set \n","    trains, valids, tr_labels, val_labels = k_split(kmnist_data, kmnist_labels, splits=k_folds)\n","\n","    \n","    if k_folds==1:\n","      train_mean, val_mean, train_std, val_std = get_mean_std(trains, valids)\n","\n","      k_train = CustomImageTensorDataset(trains, tr_labels, transform=transformed(train_mean, train_std, choice=1))\n","      k_validate = CustomImageTensorDataset(valids, val_labels, transform=transformed(val_mean, val_std, choice=1))\n","\n","      # View this in 2d for pca \n","      x_tr = k_train.data.view(len(k_train.data), 28*28)\n","      x_te = k_validate.data.view(len(k_validate.data), 28*28)\n","      \n","      ac, loss, y_pred = None, None, None\n","\n","      if (classifier == 0):\n","        ac, loss, y_pred = pca_kneighbours(x_tr, k_train.targets, x_te, k_validate.targets, n_component=n_components, neigh_num=neigh_num); # KNN\n","\n","      if (classifier == 1):\n","        ac, loss, y_pred = pca_randomforest(x_tr, k_train.targets, x_te, k_validate.targets, n_component=n_components, n_estimator=100, max_depth=25); # RF\n","\n","      if (classifier == 2):\n","        ac, loss, y_pred = pca_NBGauss(x_tr, k_train.targets, x_te, k_validate.targets, n_component=n_components); # NB\n","        \n","\n","      # Final validation accuracy is the average of all the validation sets  \n","      return ac, loss, y_pred\n","\n","    else:\n","      \n","      # Save the list of accuracy score\n","      acs = [] \n","      losses = []\n","      \n","      # Save max accuracy and corresponding y_pred \n","      max_acc = 0.0\n","      max_y_pred = None\n","\n","      for i in range(k_folds):\n","        # Get the mean and std of training and validation set\n","        train_mean, val_mean, train_std, val_std = get_mean_std(trains[i], valids[i])\n","\n","        k_train = CustomImageTensorDataset(trains[i], tr_labels[i], transform=transformed(train_mean, train_std, choice=1))\n","        k_validate = CustomImageTensorDataset(valids[i], val_labels[i], transform=transformed(val_mean, val_std, choice=1))\n","\n","        # View this in 2d for pca \n","        x_tr = k_train.data.view(len(k_train.data), 28*28)\n","        x_te = k_validate.data.view(len(k_validate.data), 28*28)\n","        \n","        ac, loss, y_pred = None, None, None\n","\n","        if (classifier == 0):\n","          ac, loss, y_pred = pca_kneighbours(x_tr, k_train.targets, x_te, k_validate.targets, n_component=n_components, neigh_num=neigh_num)\n","\n","        if (classifier == 1):\n","          ac, loss, y_pred = pca_randomforest(x_tr, k_train.targets, x_te, k_validate.targets, n_component=n_components, n_estimator=100, max_depth=30)\n","\n","        if (classifier == 2):\n","          ac, loss, y_pred = pca_NBGauss(x_tr, k_train.targets, x_te, k_validate.targets, n_component=n_components)\n","\n","        acs.append(ac)\n","        losses.append(loss)\n","        \n","        if ac > max_acc:\n","          max_acc = ac\n","          max_y_pred = y_pred\n","          \n","        # Final validation accuracy is the average of all the validation sets  \n","        # Alse return prediction with highest accuracy\n","        return np.asarray(acs).mean(), np.asarray(losses).mean(), max_y_pred\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mlElUdLo7p4r","colab_type":"text"},"source":["### Run classifying function"]},{"cell_type":"code","metadata":{"id":"Y6uDUgNiTTpj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":117},"outputId":"4a4f0a00-7764-4cfd-d28c-00c33284fc30","executionInfo":{"status":"ok","timestamp":1558610778429,"user_tz":-60,"elapsed":127499,"user":{"displayName":"Adanna Akwataghibe","photoUrl":"","userId":"13306086339002156366"}}},"source":["print(\"PCA with KNN Classifier\")\n","res_knn_acc, res_knn_loss, res_knn_preds = test_pca_classifier(classifier=0, neigh_num=4, n_components=80, k_folds=1)\n","print(\"Accuracy, Loss: \", res_knn_acc, res_knn_loss)\n","\n","print(\"PCA with Random Forrest Classifier\")\n","res_rf_acc, res_rf_loss, res_rf_preds = test_pca_classifier(classifier=1, n_components=40, k_folds=1)\n","print(\"Accuracy, Loss: \", res_rf_acc, res_rf_loss)\n","\n","print(\"PCA with Naive-Bayes Classifier\")\n","res_nb_acc, res_nb_loss, res_nb_preds = test_pca_classifier(classifier=2, n_components=40, k_folds=1)\n","print(\"Accuracy, Loss: \", res_nb_acc, res_nb_loss)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["PCA with KNN Classifier\n","Accuracy, Loss:  97.66666666666667 2.3333333333333335\n","PCA with Random Forrest Classifier\n","Accuracy, Loss:  93.51666666666667 6.483333333333333\n","PCA with Naive-Bayes Classifier\n","Accuracy, Loss:  76.56666666666666 23.433333333333334\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KlE2W-PCW8oM","colab_type":"text"},"source":["## 6. Predict the test set"]},{"cell_type":"code","metadata":{"id":"NaMmP-LFWEhz","colab_type":"code","colab":{}},"source":["# View this in 2d for pca \n","x_tr = kmnist_data.data.view(len(kmnist_data), 28*28)\n","x_te = kmnist_test.data.view(len(kmnist_test), 28*28)\n","\n","_, _, y_preds = pca_kneighbours(x_tr, kmnist_labels, x_te, n_component=80, neigh_num=4, evaluate=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"otBp30Gu7uAX","colab_type":"text"},"source":["## 7. Save  predictions to csv file"]},{"cell_type":"code","metadata":{"id":"KQmN5PF77LmL","colab_type":"code","colab":{}},"source":["save_predictions_ns(y_preds, name=\"pca_classifier_preds\")"],"execution_count":0,"outputs":[]}]}